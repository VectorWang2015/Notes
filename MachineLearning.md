# 机器学习 周志华
```
 __  __            _     _            
|  \/  | __ _  ___| |__ (_)_ __   ___ 
| |\/| |/ _` |/ __| '_ \| | '_ \ / _ \
| |  | | (_| | (__| | | | | | | |  __/
|_|  |_|\__,_|\___|_| |_|_|_| |_|\___|
                                      
 _                          _             
| |    ___  __ _ _ __ _ __ (_)_ __   __ _ 
| |   / _ \/ _` | '__| '_ \| | '_ \ / _` |
| |__|  __/ (_| | |  | | | | | | | | (_| |
|_____\___|\__,_|_|  |_| |_|_|_| |_|\__, |
                                    |___/ 
```
[toc]

## 第一章 绪论
<p style="text-align: center;"><img src="./img/ML-1.0.png" width=600/></p>
机器学习是什么:  
利用经验改善系统性能

### 基础概念
| 术语                 |                                                       |
|----------------------|-------------------------------------------------------|
| 监督学习vs无监督学习 | 监督学习:训练数据有标签                               |
| 分类,回归,聚类       | 回归:目标标签是连续值 聚类:将训练集中的样本分为若干簇 |
| 数据,样本,标签       |                                                       |
| 假设空间             | g的候选集合,学习过程就是从假设空间进行搜索的过程      |
| 版本空间             | 与训练集一致的假设的集合                              |


### NFL定理
没有免费的午餐定理:  
一个算法若再某些问题上比另一个算法好,则一定存在另一些问题,使后一算法优于前者  

$$
E_{ote}(\mathfrak L_a | X,f) = \sum_h \sum_{x \in \mathcal X-X} P(x)\mathrm{II}(h(x) \neq f(x))P(h | X, \mathfrak L_a)
$$

### 习题
1.2 穷举法程序见./programs  
